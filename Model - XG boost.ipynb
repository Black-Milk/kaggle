{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 4\n",
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.io import *\n",
    "from fastai.structured import *\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from pandas_summary import DataFrameSummary\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "import feather\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = feather.read_dataframe('train_df_alpha')\n",
    "test_df2 = feather.read_dataframe('test_df_alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df2, test_df2]:\n",
    "    for f in ['purchase_date_max','purchase_date_min','purchase_date_max_old',\\\n",
    "                     'purchase_date_min_old', 'observation_date_old']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_excluded = ['purchase_date_max', 'purchase_date_max_old', 'card_id', 'first_active_month',\n",
    "                 'target','outliers','card_id_size', 'card_id_size_old', \n",
    "                 'purchase_date_min', 'purchase_date_min_old','first_active_monthYear',\n",
    "                 'first_active_monthMonth',\n",
    "                 'first_active_monthWeek',\n",
    "                 'first_active_monthDay',\n",
    "                 'first_active_monthDayofweek',\n",
    "                 'first_active_monthDayofyear',\n",
    "                 'first_active_monthIs_month_end',\n",
    "                 'first_active_monthIs_month_start',\n",
    "                 'first_active_monthIs_quarter_end',\n",
    "                 'first_active_monthIs_quarter_start',\n",
    "                 'first_active_monthIs_year_end',\n",
    "                 'Black_Friday_2017_mean',\n",
    "                 'amount_month_ratio_max',\n",
    "                 'purchase_Month_mean_old',\n",
    "                 'purchase_amount_total_max',\n",
    "                 'first_active_monthIs_year_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cols_included = ['feature_1','feature_2','feature_3','transactions_count','subsector_id_nunique','merchant_id_nunique','merchant_category_id_nunique','purchase_Month_mean','purchase_Month_min','purchase_Month_max','purchase_Week_nunique','purchase_Week_mean','purchase_Week_min','purchase_Week_max','purchase_Dayofweek_mean','purchase_Dayofweek_min','purchase_Dayofweek_max','purchase_Day_nunique','purchase_Day_mean','purchase_Day_min','purchase_Day_max','purchase_Hour_nunique','purchase_Hour_mean','purchase_Hour_min','purchase_Hour_max','purchase_amount_sum','purchase_amount_max','purchase_amount_min','purchase_amount_mean','purchase_amount_var','purchase_amount_skew','installments_sum','installments_max','installments_mean','installments_var','installments_skew','month_lag_max','month_lag_min','month_lag_mean','month_lag_var','month_lag_skew','month_diff_mean','month_diff_var','month_diff_skew','purchased_on_weekend_mean','category_1_mean','category_2_mean','category_3_mean','card_id_count','price_mean','price_max','price_min','price_var','Christmas_Day_2017_mean','Children_day_2017_mean','Black_Friday_2017_mean','Mothers_Day_2018_mean','duration_mean','duration_min','duration_max','duration_var','duration_skew','amount_month_ratio_mean','amount_month_ratio_min','amount_month_ratio_max','amount_month_ratio_var','amount_month_ratio_skew','category_2_mean_mean','category_3_mean_mean','purchase_date_diff','purchase_date_average','purchase_date_uptonow','purchase_date_uptomin','transactions_count_old','subsector_id_nunique_old','merchant_id_nunique_old','merchant_category_id_nunique_old','purchase_Month_nunique','purchase_Month_mean_old','purchase_Month_min_old','purchase_Month_max_old','purchase_Week_nunique_old','purchase_Week_mean_old','purchase_Week_min_old','purchase_Week_max_old','purchase_Dayofweek_mean_old','purchase_Day_nunique_old','purchase_Day_mean_old','purchase_Day_min_old','purchase_Hour_nunique_old','purchase_Hour_mean_old','purchase_Hour_min_old','purchase_Hour_max_old','purchase_amount_sum_old','purchase_amount_max_old','purchase_amount_min_old','purchase_amount_mean_old','purchase_amount_var_old','purchase_amount_skew_old','installments_sum_old','installments_max_old','installments_mean_old','installments_var_old','installments_skew_old','month_lag_max_old','month_lag_min_old','month_lag_mean_old','month_lag_var_old','month_lag_skew_old','month_diff_max','month_diff_min','month_diff_mean_old','month_diff_var_old','month_diff_skew_old','authorized_flag_mean','purchased_on_weekend_mean_old','category_1_mean_old','category_2_mean_old','category_3_mean_old','card_id_count_old','price_sum','price_mean_old','price_max_old','price_min_old','price_var_old','Christmas_Day_2017_mean_old','Mothers_Day_2017_mean','fathers_day_2017_mean','Children_day_2017_mean_old','Valentine_Day_2017_mean','Black_Friday_2017_mean_old','Mothers_Day_2018_mean_old','duration_mean_old','duration_min_old','duration_max_old','duration_var_old','duration_skew_old','amount_month_ratio_mean_old','amount_month_ratio_min_old','amount_month_ratio_max_old','amount_month_ratio_var_old','amount_month_ratio_skew_old','category_2_mean_mean_old','category_3_mean_mean_old','purchase_date_diff_old','purchase_date_average_old','purchase_date_uptonow_old','purchase_date_uptomin_old','quarter','observed_elapsed_time','days_feature1','days_feature2','days_feature3','days_feature1_ratio','days_feature2_ratio','days_feature3_ratio','feature_sum','feature_mean','feature_max','feature_min','feature_var','card_id_total','card_id_count_total','card_id_count_ratio','purchase_amount_total','purchase_amount_total_mean','purchase_amount_total_max','purchase_amount_total_min','purchase_amount_sum_ratio','hist_first_buy','new_first_buy','hist_last_buy','new_last_buy','month_diff_ratio','installments_total','installments_ratio','price_total','CLV','CLV_old','CLV_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns = [c for c in cols_included if c not in cols_excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_cols = ['merchant_address_id_nunique', 'merchant_rating_nunique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns = df_train_columns + extra_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'reg:linear', \n",
    "    'eval_metric': 'rmse', \n",
    "    'silent': True, \n",
    "    'booster': 'gbtree', \n",
    "    'n_jobs': 4, \n",
    "    'n_estimators': 20000, \n",
    "    'grow_policy': 'lossguide', \n",
    "    'max_depth': 12, \n",
    "    'seed': 538, \n",
    "    'colsample_bylevel': 0.9, \n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.0001, \n",
    "    'learning_rate': 0.006150886706231842, \n",
    "    'max_bin': 128, \n",
    "    'max_leaves': 47, \n",
    "    'min_child_weight': 40, \n",
    "    'reg_alpha': 10.0, \n",
    "    'reg_lambda': 10.0, \n",
    "    'silent': True,\n",
    "    'eta': 0.005,\n",
    "    'subsample': 0.9\n",
    "}\n",
    "\n",
    "# xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "#           'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_xgb_3 = np.zeros(len(train_df2))\n",
    "predictions_xgb_3 = np.zeros(len(test_df2))\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Fold 1\n",
      "xgb 0--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.94728\tvalid-rmse:3.95376\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:2.87719\tvalid-rmse:3.65189\n",
      "Stopping. Best iteration:\n",
      "[682]\ttrain-rmse:2.98069\tvalid-rmse:3.65003\n",
      "\n",
      "-\n",
      "Fold 2\n",
      "xgb 1--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.94767\tvalid-rmse:3.95308\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:2.88087\tvalid-rmse:3.66125\n",
      "Stopping. Best iteration:\n",
      "[1170]\ttrain-rmse:2.83974\tvalid-rmse:3.66092\n",
      "\n",
      "-\n",
      "Fold 3\n",
      "xgb 2--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.95058\tvalid-rmse:3.94095\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:2.89968\tvalid-rmse:3.65298\n",
      "Stopping. Best iteration:\n",
      "[617]\ttrain-rmse:3.03102\tvalid-rmse:3.64978\n",
      "\n",
      "-\n",
      "Fold 4\n",
      "xgb 3--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.94875\tvalid-rmse:3.94851\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:2.8861\tvalid-rmse:3.63722\n",
      "Stopping. Best iteration:\n",
      "[674]\ttrain-rmse:2.99153\tvalid-rmse:3.63405\n",
      "\n",
      "-\n",
      "Fold 5\n",
      "xgb 4--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.94758\tvalid-rmse:3.9529\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:2.88577\tvalid-rmse:3.65254\n",
      "Stopping. Best iteration:\n",
      "[1115]\ttrain-rmse:2.85861\tvalid-rmse:3.65244\n",
      "\n",
      "CPU times: user 6h 45min 49s, sys: 5.76 s, total: 6h 45min 55s\n",
      "Wall time: 1h 7min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df2,train_df2['outliers'].values)):    \n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(data=train_df2.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = xgb.DMatrix(data=train_df2.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "    print(\"xgb \" + str(fold_) + \"-\" * 50)\n",
    "    num_round = 10000\n",
    "    xgb_model = xgb.train(xgb_params, trn_data, num_round, watchlist, early_stopping_rounds=500, verbose_eval=1000)\n",
    "    oof_xgb_3[val_idx] = xgb_model.predict(xgb.DMatrix(train_df2.iloc[val_idx][df_train_columns]), ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "\n",
    "    predictions_xgb_3 += xgb_model.predict(xgb.DMatrix(test_df2[df_train_columns]), ntree_limit=xgb_model.best_ntree_limit+50) / folds.n_splits\n",
    "    \n",
    "np.save('oof_xgb_3_2', oof_xgb_3)\n",
    "np.save('predictions_xgb_3_2', predictions_xgb_3)\n",
    "np.sqrt(mean_squared_error(target.values, oof_xgb_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_xgb_3_2 = np.load('oof_xgb_3_2.npy')\n",
    "predictions_xgb_3_2 = np.load('predictions_xgb_3_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_xgb_3 = np.load('oof_xgb_3.npy')\n",
    "# predictions_xgb_3_2 = np.load('predictions_xgb_3_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.649844028552147"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(target.values, oof_xgb_3_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(mean_squared_error(target.values, oof_xgb_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = pd.to_datetime(\"today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":test_df2[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions_xgb_3\n",
    "sub_df.to_csv(f'xg_submission-{submission_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'xg_submission-{submission_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xg_submission-2019-02-21 11:18:00.066865.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|#######################################| 4.24M/4.24M [00:05<00:00, 798kB/s]\n",
      "Successfully submitted to Elo Merchant Category Recommendation"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit elo-merchant-category-recommendation -f 'xg_submission-2019-02-21 11:18:00.066865.csv' -m \"xgboost with 180 cols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columnsnse_cols = ['Black_Friday_2017_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns = [c for c in df_train_columns if c not in remove_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.63714\tvalid_1's rmse: 3.70315\n",
      "[200]\ttraining's rmse: 3.54887\tvalid_1's rmse: 3.66357\n",
      "[300]\ttraining's rmse: 3.49898\tvalid_1's rmse: 3.65138\n",
      "[400]\ttraining's rmse: 3.46344\tvalid_1's rmse: 3.64693\n",
      "[500]\ttraining's rmse: 3.43717\tvalid_1's rmse: 3.64506\n",
      "[600]\ttraining's rmse: 3.41561\tvalid_1's rmse: 3.64369\n",
      "[700]\ttraining's rmse: 3.39611\tvalid_1's rmse: 3.64378\n",
      "[800]\ttraining's rmse: 3.37645\tvalid_1's rmse: 3.64344\n",
      "[900]\ttraining's rmse: 3.36122\tvalid_1's rmse: 3.64357\n",
      "[1000]\ttraining's rmse: 3.34474\tvalid_1's rmse: 3.64395\n",
      "Early stopping, best iteration is:\n",
      "[833]\ttraining's rmse: 3.37103\tvalid_1's rmse: 3.64336\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.63889\tvalid_1's rmse: 3.6947\n",
      "[200]\ttraining's rmse: 3.55007\tvalid_1's rmse: 3.65835\n",
      "[300]\ttraining's rmse: 3.49857\tvalid_1's rmse: 3.64708\n",
      "[400]\ttraining's rmse: 3.46521\tvalid_1's rmse: 3.64355\n",
      "[500]\ttraining's rmse: 3.43907\tvalid_1's rmse: 3.64183\n",
      "[600]\ttraining's rmse: 3.41827\tvalid_1's rmse: 3.64112\n",
      "[700]\ttraining's rmse: 3.39818\tvalid_1's rmse: 3.64107\n",
      "[800]\ttraining's rmse: 3.37936\tvalid_1's rmse: 3.64096\n",
      "[900]\ttraining's rmse: 3.3619\tvalid_1's rmse: 3.64108\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's rmse: 3.3821\tvalid_1's rmse: 3.64082\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.63516\tvalid_1's rmse: 3.70406\n",
      "[200]\ttraining's rmse: 3.54604\tvalid_1's rmse: 3.66915\n",
      "[300]\ttraining's rmse: 3.49759\tvalid_1's rmse: 3.65914\n",
      "[400]\ttraining's rmse: 3.4638\tvalid_1's rmse: 3.65501\n",
      "[500]\ttraining's rmse: 3.43881\tvalid_1's rmse: 3.65295\n",
      "[600]\ttraining's rmse: 3.4191\tvalid_1's rmse: 3.65205\n",
      "[700]\ttraining's rmse: 3.40104\tvalid_1's rmse: 3.6516\n",
      "[800]\ttraining's rmse: 3.38329\tvalid_1's rmse: 3.65136\n",
      "[900]\ttraining's rmse: 3.36524\tvalid_1's rmse: 3.65102\n",
      "[1000]\ttraining's rmse: 3.34891\tvalid_1's rmse: 3.65104\n",
      "[1100]\ttraining's rmse: 3.33225\tvalid_1's rmse: 3.651\n",
      "[1200]\ttraining's rmse: 3.31609\tvalid_1's rmse: 3.65142\n",
      "Early stopping, best iteration is:\n",
      "[1064]\ttraining's rmse: 3.33836\tvalid_1's rmse: 3.65079\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.63738\tvalid_1's rmse: 3.69658\n",
      "[200]\ttraining's rmse: 3.5482\tvalid_1's rmse: 3.66116\n",
      "[300]\ttraining's rmse: 3.49658\tvalid_1's rmse: 3.65039\n",
      "[400]\ttraining's rmse: 3.46148\tvalid_1's rmse: 3.64691\n",
      "[500]\ttraining's rmse: 3.43706\tvalid_1's rmse: 3.64464\n",
      "[600]\ttraining's rmse: 3.41643\tvalid_1's rmse: 3.64321\n",
      "[700]\ttraining's rmse: 3.39846\tvalid_1's rmse: 3.64288\n",
      "[800]\ttraining's rmse: 3.38313\tvalid_1's rmse: 3.6425\n",
      "[900]\ttraining's rmse: 3.36699\tvalid_1's rmse: 3.64232\n",
      "[1000]\ttraining's rmse: 3.35152\tvalid_1's rmse: 3.64233\n",
      "[1100]\ttraining's rmse: 3.33564\tvalid_1's rmse: 3.64201\n",
      "[1200]\ttraining's rmse: 3.3181\tvalid_1's rmse: 3.64232\n",
      "Early stopping, best iteration is:\n",
      "[1074]\ttraining's rmse: 3.34029\tvalid_1's rmse: 3.64188\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.6389\tvalid_1's rmse: 3.68553\n",
      "[200]\ttraining's rmse: 3.5482\tvalid_1's rmse: 3.65443\n",
      "[300]\ttraining's rmse: 3.49408\tvalid_1's rmse: 3.64658\n",
      "[400]\ttraining's rmse: 3.46145\tvalid_1's rmse: 3.64418\n",
      "[500]\ttraining's rmse: 3.44013\tvalid_1's rmse: 3.64287\n",
      "[600]\ttraining's rmse: 3.4215\tvalid_1's rmse: 3.64224\n",
      "[700]\ttraining's rmse: 3.40468\tvalid_1's rmse: 3.64217\n",
      "[800]\ttraining's rmse: 3.38764\tvalid_1's rmse: 3.64246\n",
      "Early stopping, best iteration is:\n",
      "[623]\ttraining's rmse: 3.41741\tvalid_1's rmse: 3.64206\n",
      "3.6437856343297264 CV score\n",
      "CPU times: user 12min 19s, sys: 5.12 s, total: 12min 24s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_fold = 5\n",
    "param = {\n",
    "        'task': 'train',\n",
    "        'boosting': 'goss',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': 0.01,\n",
    "        'subsample': 0.9855232997390695,\n",
    "        'max_depth': 7,\n",
    "        'top_rate': 0.9064148448434349,\n",
    "        'num_leaves': 123,\n",
    "        'min_child_weight': 41.9612869171337,\n",
    "        'other_rate': 0.0721768246018207,\n",
    "        'reg_alpha': 9.677537745007898,\n",
    "        'colsample_bytree': 0.5665320670155495,\n",
    "        'min_split_gain': 9.820197773625843,\n",
    "        'reg_lambda': 8.2532317400459,\n",
    "        'min_data_in_leaf': 21,\n",
    "        'verbose': -1,\n",
    "        'seed':int(2**n_fold),\n",
    "        'bagging_seed':int(2**n_fold),\n",
    "        'drop_seed':int(2**n_fold)\n",
    "        }\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=4590)\n",
    "oof = np.zeros(len(train_df2))\n",
    "predictions = np.zeros(len(test_df2))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df2,train_df2['outliers'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df2.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df2.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(train_df2.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = df_train_columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df2[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(np.sqrt(mean_squared_error(oof, target)), 'CV score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('oof_lgbm', oof)\n",
    "np.save('predictions_lgbm', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6416503351286953"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack = np.vstack([oof, oof_xgb_3_2]).transpose()\n",
    "test_stack = np.vstack([predictions, predictions_xgb_3_2]).transpose()\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_stacked = np.zeros(train_stack.shape[0])\n",
    "predictions_stacked = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, train_df2['outliers'].values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "\n",
    "    clf = Ridge(alpha=1)\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stacked[val_idx] = clf.predict(val_data)\n",
    "    predictions_stacked += clf.predict(test_stack) / folds.n_splits\n",
    "\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(target.values, oof_stacked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Round 1\n",
    "    - XGB - 3.653676915307743 - LB -3.696 - small number of params\n",
    "    - LGB - 3.644578037274131\n",
    "    - Stacked - 3.6427847564989353\n",
    "1. Round 2\n",
    "    - XGB - 3.649741559823745 - LB -3.696 - fine tuned params from kernel\n",
    "    - LGB - 3.644578037274131\n",
    "    - Stacked - 3.6422567644144066\n",
    "2. Round 3 - added ['merchant_address_id_nunique', 'merchant_rating_nunique']\n",
    "    - XGB - 3.649806733419173\n",
    "    - LGB - 3.6445206627403186 CV score\n",
    "    - Stacked - 3.6421515201025905\n",
    "    - LGB - 3.644042133990217 CV score (without Black_Friday_2017_mean)\n",
    "    - Stacked - 3.641770180430725 (without Black_Friday_2017_mean)\n",
    "1. Round 4\n",
    "    - XGB - 3.649844028552147\n",
    "    - LGB - 3.6437856343297264 \n",
    "    - Stacked - 3.6416503351286953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = pd.to_datetime(\"today\")\n",
    "sub_df = pd.DataFrame({\"card_id\":test_df2[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions_stacked\n",
    "sub_df.to_csv(f'xg_submission_stacked_lgb-{submission_name}.csv', index=False)\n",
    "filename = f'xg_submission_stacked_lgb-{submission_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xg_submission_stacked_lgb-2019-02-22 20:48:54.579689.csv'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|############################1          | 3.06M/4.24M [00:12<00:03, 310kB/s]^C\n",
      " 79%|##############################6        | 3.33M/4.24M [00:13<00:03, 264kB/s]\n",
      "User cancelled operation\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit elo-merchant-category-recommendation -f 'xg_submission_stacked_lgb-2019-02-21 13:41:48.181414.csv' -m \"xgboost & lgbm stacked with 180 cols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
